{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook on Computer vision Crowd Counting\n",
    "\n",
    "(Version 1.0)\n",
    "\n",
    "<img src=\"pictures/TDI_logo.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook gives a summary of the machine learning model we used in this tool.  \n",
    "\n",
    "<br>\n",
    "\n",
    "**Explain the ML project here with a detailed description...**\n",
    "\n",
    "> More project description here:\n",
    "\n",
    "Crowd Counting is a common application of computer vision. There are constantly new algorithms that are being invented as research is still active in this area. Our business case, however, drives our model selection. I've built and compared three approaches and I'll include some introduction on each of them in the later part of the document.\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "**Explain this notebook's results here...**\n",
    "\n",
    "\n",
    "> The model selection space:\n",
    "\n",
    "> * Cascade Classifier Algorithm (Cascade)\n",
    "> * Tensorflow based Fast-Regions with CNN (RCNN)\n",
    "> * Pytorch-based Congested Scenes RNet (CSRNet)\n",
    "\n",
    "\n",
    "> We discuss and compare these 3 models and include some code nippets. \n",
    "\n",
    "> * Cascade is common for object detection and it's fast. In our business case it's possible to run detection on restaurant's video frames almost in real time.\n",
    "> * Problem with Cascase is that it's based on frontal face detection so accuracy drops when customer do not show face in the camera.\n",
    "> * RCNN is taking 2000 region proposals to feed into a CNN so computational speed is slow. Fast RCNN resolves this by using a heat map. Faster RCNN is even faster by adding a separate network so can also almost achieve real-time.\n",
    "> * Problem with RCNN is that the approach is new (from 2016) and there aren't many transfer learning model to use. When I trained my own model I found that it suffers from occulation (the scenario when crowd is dense and people covers each other). RCNN performs poorly when person do not have full body in the picture. occlusion-aware R-CNN is an active research area.\n",
    "> * CSRNet use separate columns to handle the problem with different head size it's also more flexible on the input image size (sort of a one-size-fits-all solution). So could be generalized easily if commercialized.\n",
    "> * CSRNet is density based and performs well in counting large crowds over 300+ people. I used Google Collab to train on the cloud using Pytorch, as I do not have a CUDA enabled GPU on my machine. I did not observe any advantage in either speed or accuracy in our case as our crowd is usually less than 50.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cascade approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Github\\menu\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Apr 30 00:28:47 2020\n",
    "Cascade is native in OpenCV (import as cv2). The trained classifer is saved as a XML file.\n",
    "@author: georgehan\n",
    "\"\"\"\n",
    "import os\n",
    "#os.chdir('/Users/georgehan/TDI/Capstone/Smart_Menu')\n",
    "#os.chdir('/Users/georgehan/GitHub/menu')\n",
    "print(os.getcwd())\n",
    "#os.chdir(os.getcwd())\n",
    "import cv2\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pictures/mcd_short.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 customers!\n",
      "Hyperparameters are scaleFactor, minNeighbors, and minSize.\n"
     ]
    }
   ],
   "source": [
    "imagePath = \"pictures/mcd_short.jpg\"\n",
    "trainedWeights = \"trained_customer.xml\"\n",
    "\n",
    "customerTrainedWeights =  cv2.CascadeClassifier(trainedWeights)\n",
    "\n",
    "# Read the image\n",
    "image = cv2.imread(imagePath)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# detect customer in pic\n",
    "\n",
    "customers = customerTrainedWeights.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.2, # controlls fine (smaller) vs coarse (larger) trade off, needs to > 1.0\n",
    "        minNeighbors=5, # used to combine overlapping small boxes into big one\n",
    "        minSize=(60, 40) # box size, distance between recoginized customers\n",
    ")\n",
    "\n",
    "print(\"Found {0} customers!\".format(len(customers)))\n",
    "print(\"Hyperparameters are scaleFactor, minNeighbors, and minSize.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image written to file-system :  True\n",
      "pictures/mcd_very_long.jpg\n"
     ]
    }
   ],
   "source": [
    "# Draw a rectangle around the customers\n",
    "for (x, y, w, h) in customers:\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "# cv2.imshow(\"customers found\", image)\n",
    "status = cv2.imwrite('customers_detect.jpg', image)\n",
    "print (\"Image written to file-system : \",status)\n",
    "print(imagePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"mcd_short_marked.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Cascade approach can read more at:** http://www.willberger.org/cascade-haar-explained/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faster R-CNN approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RCNN uses OpenCV and tensorflow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/georgehan/GitHub/menu'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the main class for counting customers\n",
    "class customer_Counter:\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.detection_graph = tf.Graph()\n",
    "        with self.detection_graph.as_default():\n",
    "            od_graph_def = tf.GraphDef()\n",
    "            with tf.gfile.GFile(self.path, 'rb') as fid:\n",
    "                serialized_graph = fid.read()\n",
    "                od_graph_def.ParseFromString(serialized_graph)\n",
    "                tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "        self.default_graph = self.detection_graph.as_default()\n",
    "        self.sess = tf.Session(graph=self.detection_graph)\n",
    "\n",
    "        self.image_tensor = self.detection_graph.get_tensor_by_name('image_tensor:0') # Defining tensors for the graph\n",
    "        self.detection_boxes = self.detection_graph.get_tensor_by_name('detection_boxes:0') # Each box denotes part of image with a person detected \n",
    "        self.detection_scores = self.detection_graph.get_tensor_by_name('detection_scores:0') # Score represents the confidence for the detected person\n",
    "        self.detection_classes = self.detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        self.num_detections = self.detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "    def detect(self, image):\n",
    "        image_np_expanded = np.expand_dims(image, axis=0)\n",
    "        (boxes, scores, classes, num) = self.sess.run(\n",
    "            [self.detection_boxes, self.detection_scores, self.detection_classes, self.num_detections],\n",
    "            feed_dict={self.image_tensor: image_np_expanded}) # Using the model for detection\n",
    "\n",
    "        im_height, im_width,_ = image.shape\n",
    "        boxes_list = [None for i in range(boxes.shape[1])]\n",
    "        for i in range(boxes.shape[1]):\n",
    "            boxes_list[i] = (int(boxes[0,i,0] * im_height),\n",
    "                        int(boxes[0,i,1]*im_width),\n",
    "                        int(boxes[0,i,2] * im_height),\n",
    "                        int(boxes[0,i,3]*im_width))\n",
    "\n",
    "        return boxes_list, scores[0].tolist(), [int(x) for x in classes[0].tolist()], int(num[0])\n",
    "\n",
    "    \n",
    "    def close(self):\n",
    "        self.sess.close()\n",
    "        self.default_graph.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed, RCNN model fails misearbly as it cannot detect unless has a full body of a person in the image, as shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = '../my_model.pb' \n",
    "    # This training weight is too large to upload to Github\n",
    "    customer_counter = customer_Counter(path=model_path)\n",
    "    threshold = 0.4\n",
    "    no=1\n",
    "    for n in pbar(glob.glob(\"./data/images/test/*.jpg\")):\n",
    "        count=0\n",
    "        img = cv2.imread(n)\n",
    "        img = cv2.resize(img, (640, 480))\n",
    "\n",
    "        boxes, scores, classes, num = customer_counter.detect(img)\n",
    "\n",
    "        for i in range(len(boxes)):\n",
    "            if classes[i] == 1 and scores[i] > threshold:\n",
    "                box = boxes[i]\n",
    "                cv2.rectangle(img,(box[1],box[0]),(box[3],box[2]),(255,0,0),2)\n",
    "                count+=1\n",
    "        cv2.putText(img,'Count = '+str(count),(10,400),cv2.FONT_HERSHEY_SIMPLEX, 1.25,(255,255,0),2,cv2.LINE_AA)\n",
    "        cv2.imwrite(\"./results/result%04i_menu_count.jpg\" %no, img)\n",
    "        no+=1\n",
    "print(\"\\n\\t\\t\\tCustomers Count Saved!\\n\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"RCNN_result.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Faster R-CNN can read more at**: https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSRNet-Pytorch approach:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very new model from 2018. The training can only be done on Google cloud using GPU as it takes too long. You can also accelerate it by using visdom, a computer vision open source tool from Facebook but it then requires other dependencies.\n",
    "> pip install visdom\n",
    "<br>\n",
    "> python -m visdom.server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom google.colab import drive\\ndrive.mount(\\'/content/drive/\\')\\n\\nimport os\\nos.chdir(\"/content/drive/My Drive/app/CSRNet-pytorch\")\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code is for running on google.colab \n",
    "# a cloud environment with GPU enabled.\n",
    "'''\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "import os\n",
    "os.chdir(\"/content/drive/My Drive/app/CSRNet-pytorch\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main training script is as following. Note that if you do not have CUDA enabled GPU, then you need to use: \n",
    "> device = torch.device(\"cude:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of CSRNet using Pytorch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "```python\n",
    "import h5py\n",
    "import scipy.io as io\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.ndimage.filters import gaussian_filter \n",
    "import scipy\n",
    "import json\n",
    "import torchvision.transforms.functional as F\n",
    "from matplotlib import cm as CM\n",
    "from image import *\n",
    "from model import CSRNet\n",
    "import torch\n",
    "%matplotlib inline\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225]),\n",
    "                   ])\n",
    "\n",
    "\n",
    "root = '/content/drive/My Drive/app/CSRNet-pytorch/data/'\n",
    "\n",
    "\n",
    "#now generate the training data's ground truth\n",
    "part_A_train = os.path.join(root,'part_A_final/train_data','images')\n",
    "part_A_test = os.path.join(root,'part_A_final/test_data','images')\n",
    "part_B_train = os.path.join(root,'part_B_final/train_data','images')\n",
    "part_B_test = os.path.join(root,'part_B_final/test_data','images')\n",
    "path_sets = [part_A_test]\n",
    "\n",
    "img_paths = []\n",
    "for path in path_sets:\n",
    "    for img_path in glob.glob(os.path.join(path, '*.jpg')):\n",
    "        img_paths.append(img_path)\n",
    "        \n",
    "        \n",
    "model = CSRNet()\n",
    "model = model.cuda()\n",
    "checkpoint = torch.load('0model_best.pth.tar') \n",
    "# Again this trained model is 130mb too big for Github\n",
    "# so not included in the folder\n",
    "\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "from matplotlib import cm as c\n",
    "import matplotlib.image as mpimg\n",
    "img = transform(Image.open('/content/drive/My Drive/app/CSRNet-pytorch/mcd_very_long.jpg').convert('RGB')).cuda()\n",
    "\n",
    "output = model(img.unsqueeze(0))\n",
    "print(\"Predicted Count : \",int(output.detach().cpu().sum().numpy()))\n",
    "temp = np.asarray(output.detach().cpu().reshape(output.detach().cpu().shape[2],output.detach().cpu().shape[3]))\n",
    "plt.figure\n",
    "f, axarr = plt.subplots(1,2)\n",
    "axarr[0].imshow(temp,cmap = c.jet)\n",
    "axarr[1].imshow(mpimg.imread('/content/drive/My Drive/app/CSRNet-pytorch/mcd_very_long.jpg'))\n",
    "plt.show()\n",
    "        \n",
    "        \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model implementation script is saved in CSRNet_pytorch folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"CSRNet_result.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSRNet is very effective when there's a large crowd as it has a better ability to detect people with small heads. However, when the number of people in the picture is less, it tends to overcount as it uses a density based approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can read more on the ideas of CSRNet at:** https://medium.com/secure-and-private-ai-writing-challenge/implementation-of-csrnet-crowd-counting-project-for-udacity-project-showcase-a451b4397d71"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, considering the restaurant needs real-time speed, with reasonable accuracy and close up cameras. We choose Cascade classifier as it makes the most business sense. \n",
    "\n",
    "> - The number of people is usually small. \n",
    "> - The distance from the camera to the crowd is near.\n",
    "\n",
    "We can overcome the draw back of face detection requirement by placing the detection camera always facing the customer queue.\n",
    "<br>\n",
    "<br>\n",
    "This model selection is based on business case scenario.\n",
    "\n",
    "<br>\n",
    "Can add more here... on possible extensions. Feasibiliy of the this tool etc...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
